{"nbformat":4,"nbformat_minor":5,"metadata":{"notebookId":"00533839-d306-4f61-80bd-7d10d55b2a4f","language_info":{"file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3"},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"code","source":"#!c1.8\n# nusc_path = '/home/jupyter/work/resources/data/nuscenes_mini'\n# prediction_path = '/home/jupyter/work/resources/monolayout_vkr/models/nu_gan_mclass_static/nu_mini/output/static'\n# gt_path = os.path.join(nusc_path, 'static_gt')\n# nusc_version = 'v1.0-mini'\n\nnusc_path = '/home/jupyter/work/resources/data/nuscenes'\nprediction_path = '/home/jupyter/work/resources/monolayout_vkr/models/nu_gan_mclass_static/output/static'\ngt_path = os.path.join(nusc_path, 'static_gt')\nnusc_version = 'v1.0-trainval'","metadata":{"cellId":"dz4t09k06ofo2lmqafej8","trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"#!c1.8\nimport argparse\nimport os\n\nfrom matplotlib import pyplot as plt\n\nfrom nuscenes.nuscenes import NuScenes\nfrom nuscenes.utils.data_classes import transform_matrix, Quaternion\n\nfrom nuscenes.map_expansion.map_api import NuScenesMap\nfrom nuscenes.map_expansion import arcline_path_utils\nfrom nuscenes.map_expansion.bitmap import BitMap\n\nimport numpy as np\n\nfrom PIL import Image\nfrom skimage.draw import polygon\n\nimport cv2","metadata":{"cellId":"7x8lw4xxllnzf37biu61b","trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"#!c1.8\n\ndata_root = nusc_path\nnusc = NuScenes(version=nusc_version, dataroot=data_root, verbose=True)","metadata":{"cellId":"dn7hjzuzyzshxydy8s8bmc","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"======\nLoading NuScenes tables for version v1.0-trainval...\n23 category,\n8 attribute,\n4 visibility,\n64386 instance,\n12 sensor,\n10200 calibrated_sensor,\n2631083 ego_pose,\n68 log,\n850 scene,\n34149 sample,\n2631083 sample_data,\n1166187 sample_annotation,\n4 map,\nDone loading in 57.566 seconds.\n======\nReverse indexing ...\nDone reverse indexing in 9.7 seconds.\n======\n"}],"execution_count":30},{"cell_type":"markdown","source":"# With GT","metadata":{"cellId":"39whljg03lfg9lj2g4vtgr"}},{"cell_type":"code","source":"#!c1.8\nimport glob\n\nocc_width, occ_height = 256, 256\nsensor = 'CAM_FRONT'\n\noutput_dir = f'{data_root}/video_output'\nos.makedirs(output_dir, exist_ok=True)\n\nold_location = None\nclasses = []\n\n# 12hz cams\nfps = 5\nheigth = 512\n\ngt_class_mapping = {\n    '0': 'drivable_area',\n    '1': 'ped_crossing',\n    '2': 'walkway'\n}\n\ncls_color_mapping = {\n    '0': np.array([1., 0, 0]),\n    '1': np.array([0, 1., 0]),\n    '2': np.array([0, 0, 1.])\n}\n    \nfor scene in nusc.scene:\n    out_path = os.path.join(output_dir, scene['token'], 'fetched.avi')\n    os.makedirs(os.path.join(output_dir, scene['token']), exist_ok=True)\n    \n    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'DIVX'), fps, (3 * heigth, heigth))\n\n    cur_sample_token = scene['first_sample_token']\n    \n    while cur_sample_token != \"\":\n        cur_sample = nusc.get('sample', cur_sample_token)\n        \n        cam_front_data = nusc.get('sample_data', cur_sample['data'][sensor])\n        filename = cam_front_data['filename'].split('/')[-1]\n        \n        cam_img = cv2.imread(os.path.join(nusc_path, 'samples', 'CAM_FRONT', filename))\n        cam_img = cv2.resize(cam_img, (heigth, heigth))\n        \n        if len(classes) == 0:\n            classes = sorted(os.listdir(prediction_path))\n\n        cumulative_predicted_image = 0\n        for cls_ in classes:\n            img_path = os.path.join(prediction_path, cls_, filename)\n            img = cv2.imread(img_path.replace('jpg', 'png'))\n            img = cv2.resize(img, (heigth, heigth))\n            img = np.uint8(img * cls_color_mapping[cls_])\n            cumulative_predicted_image += img\n            \n        cumulative_gt_image = 0\n        for cls_ in classes:\n            img_path = os.path.join(gt_path, gt_class_mapping[cls_], filename)\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, (heigth, heigth))\n            img = np.uint8(img * cls_color_mapping[cls_])\n            cumulative_gt_image += img \n\n\n        image = np.concatenate((cam_img, cumulative_gt_image, cumulative_predicted_image), 1) \n        out.write(image)\n                \n        cur_sample_token = cur_sample['next']\n        \n    out.release()\n","metadata":{"cellId":"t1bwswni0bjmwlnsqj10j8","execution_id":"38e01ae3-0a4a-4ad3-9156-ffa02e4ca10e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# With maps","metadata":{"cellId":"6ube3i13pgpwoa0ds04ped"}},{"cell_type":"code","source":"#!c1.8\nimport glob\n\nocc_width, occ_height = 256, 256\nsensor = 'CAM_FRONT'\n\noutput_dir = f'{data_root}/video_output'\nos.makedirs(output_dir, exist_ok=True)\n\nold_location = None\nclasses = []\n\n# 12hz cams\nfps = 5\nheigth = 512\n    \nfor scene in nusc.scene:\n    out_path = os.path.join(output_dir, scene['token'], 'fetched.avi')\n    os.makedirs(os.path.join(output_dir, scene['token']), exist_ok=True)\n    \n    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'DIVX'), fps, (3 * heigth, heigth))\n\n    log = nusc.get('log', scene['log_token'])\n\n    if old_location != log['location']:\n        nusc_map = NuScenesMap(dataroot=data_root, map_name=log['location'])\n        old_location = log['location']\n\n    cur_sample_token = scene['first_sample_token']\n    \n    \n    while cur_sample_token != \"\":\n        cur_sample = nusc.get('sample', cur_sample_token)\n        \n        cam_front_data = nusc.get('sample_data', cur_sample['data'][sensor])\n        ego_pose = nusc.get('ego_pose', cam_front_data['ego_pose_token'])\n        \n        filename = cam_front_data['filename'].split('/')[-1]\n        \n        # in meters\n        scale = 32\n\n        patch_box = [\n            ego_pose['translation'][0] - scale,\n            ego_pose['translation'][1] - scale,\n            ego_pose['translation'][0] + scale,\n            ego_pose['translation'][1] + scale\n        ]\n        \n        bitmap = BitMap(nusc_map.dataroot, nusc_map.map_name, 'basemap')\n        map_plot = nusc_map.render_map_patch(patch_box, nusc_map.non_geometric_layers, figsize=(10, 10), bitmap=bitmap)\n\n        map_plot[0].savefig('temp.png')\n        cam_img = cv2.imread(os.path.join(nusc_path, 'samples', 'CAM_FRONT', filename))\n        cam_img = cv2.resize(cam_img, (heigth, heigth))\n        map_img  = cv2.imread('temp.png')\n        map_img = cv2.resize(map_img, (heigth, heigth))\n\n        if len(classes) == 0:\n            classes = sorted(os.listdir(prediction_path))\n\n        cumulative_predicted_image = 0\n        for cls_ in classes:\n            img_path = os.path.join(prediction_path, cls_, filename)\n            img = cv2.imread(img_path.replace('jpg', 'png'))\n            img = cv2.resize(img, (heigth, heigth))\n            cumulative_predicted_image = img \n\n        image = np.concatenate((cam_img, map_img, cumulative_predicted_image), 1) \n        out.write(image)\n        \n        cur_sample_token = cur_sample['next']\n        \n    out.release()\n","metadata":{"cellId":"xm4yelknkqydie99ljjz","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Traceback (most recent call last):\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-a44faee4cc58>\", line 50, in <module>\n    map_plot = nusc_map.render_map_patch(patch_box, nusc_map.non_geometric_layers, figsize=(10, 10), bitmap=bitmap)\n  File \"/kernel/lib/python3.7/site-packages/ml_kernel/state/state.py\", line 98, in __eq__\n    self._unwrap()\n  File \"/kernel/lib/python3.7/site-packages/ml_kernel/state/state.py\", line 81, in _unwrap\n    self._self_state.load_lazy(self.varname)\n  File \"/kernel/lib/python3.7/site-packages/ml_kernel/state/state.py\", line 339, in <lambda>\n    self._ml_state.load_lazy = lambda var: load_lazy(self, var, branch)\n  File \"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py\", line 299, in _load_lazy\n    reason=REASON_LAZY_LOAD,\n  File \"/usr/lib/python3.7/concurrent/futures/_base.py\", line 430, in result\n    self._condition.wait(timeout)\n  File \"/usr/lib/python3.7/threading.py\", line 296, in wait\n    waiter.acquire()\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n    return f(*args, **kwargs)\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n    filename = getsourcefile(frame) or getfile(frame)\n  File \"/usr/lib/python3.7/inspect.py\", line 693, in getsourcefile\n    if os.path.exists(filename):\n  File \"/usr/lib/python3.7/genericpath.py\", line 19, in exists\n    os.stat(path)\nKeyboardInterrupt\nError in callback <function flush_figures at 0x7f20415858c0> (for post_execute):\nTraceback (most recent call last):\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/events.py\", line 88, in trigger\n    func(*args, **kwargs)\n  File \"/kernel/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\", line 119, in flush_figures\n    return show(True)\n  File \"/kernel/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\", line 41, in show\n    metadata=_fetch_figure_metadata(figure_manager.canvas.figure)\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/display.py\", line 313, in display\n    format_dict, md_dict = format(obj, include=include, exclude=exclude)\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/formatters.py\", line 180, in format\n    data = formatter(obj)\n  File \"/kernel/lib/python3.7/site-packages/decorator.py\", line 232, in fun\n    return caller(func, *(extras + args), **kw)\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/formatters.py\", line 224, in catch_format_error\n    r = method(self, *args, **kwargs)\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/formatters.py\", line 341, in __call__\n    return printer(obj)\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/pylabtools.py\", line 248, in <lambda>\n    png_formatter.for_type(Figure, lambda fig: print_figure(fig, 'png', **kwargs))\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/pylabtools.py\", line 132, in print_figure\n    fig.canvas.print_figure(bytes_io, **kw)\n  File \"/kernel/lib/python3.7/site-packages/matplotlib/backend_bases.py\", line 2193, in print_figure\n    self.figure.draw(renderer)\n  File \"/kernel/lib/python3.7/site-packages/matplotlib/artist.py\", line 41, in draw_wrapper\n    return draw(artist, renderer, *args, **kwargs)\n  File \"/kernel/lib/python3.7/site-packages/matplotlib/figure.py\", line 1864, in draw\n    renderer, self, artists, self.suppressComposite)\n  File \"/kernel/lib/python3.7/site-packages/matplotlib/image.py\", line 131, in _draw_list_compositing_images\n    a.draw(renderer)\n  File \"/kernel/lib/python3.7/site-packages/matplotlib/artist.py\", line 41, in draw_wrapper\n    return draw(artist, renderer, *args, **kwargs)\n  File \"/kernel/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\", line 411, in wrapper\n    return func(*inner_args, **inner_kwargs)\n  File \"/kernel/lib/python3.7/site-packages/matplotlib/axes/_base.py\", line 2747, in draw\n    mimage._draw_list_compositing_images(renderer, self, artists)\n  File \"/kernel/lib/python3.7/site-packages/matplotlib/image.py\", line 131, in _draw_list_compositing_images\n    a.draw(renderer)\n  File \"/kernel/lib/python3.7/site-packages/matplotlib/artist.py\", line 41, in draw_wrapper\n    return draw(artist, renderer, *args, **kwargs)\n  File \"/kernel/lib/python3.7/site-packages/matplotlib/image.py\", line 644, in draw\n    renderer, renderer.get_image_magnification())\n  File \"/kernel/lib/python3.7/site-packages/matplotlib/image.py\", line 929, in make_image\n    magnification, unsampled=unsampled)\n  File \"/kernel/lib/python3.7/site-packages/matplotlib/image.py\", line 407, in _make_image\n    a_min = A.min()\n  File \"/kernel/lib/python3.7/site-packages/numpy/ma/core.py\", line 5701, in min\n    axis=axis, out=out, **kwargs).view(type(self))\n  File \"/kernel/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n    return umr_minimum(a, axis, None, out, keepdims, initial, where)\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n    return f(*args, **kwargs)\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n  File \"/usr/lib/python3.7/inspect.py\", line 1464, in getframeinfo\n    lines, lnum = findsource(frame)\n  File \"/home/jupyter/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 182, in findsource\n    lines = linecache.getlines(file, globals_dict)\n  File \"/usr/lib/python3.7/linecache.py\", line 47, in getlines\n    return updatecache(filename, module_globals)\n  File \"/usr/lib/python3.7/linecache.py\", line 136, in updatecache\n    with tokenize.open(fullname) as fp:\n  File \"/usr/lib/python3.7/tokenize.py\", line 447, in open\n    buffer = _builtin_open(filename, 'rb')\nKeyboardInterrupt\n"},{"output_type":"stream","name":"stderr","text":"ERROR:root:Internal Python error in the inspect module.\nBelow is the traceback from this internal error.\n\nERROR:root:Internal Python error in the inspect module.\nBelow is the traceback from this internal error.\n\n/kernel/lib/python3.7/site-packages/ml_kernel/ignored_keyboard_interrupt.py:16: UserWarning: State committing stage cannot be interrupted. Please wait.\n  warnings.warn(self._warn_message)\n/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:817: UserWarning: The following variables cannot be serialized: out\n  warnings.warn(message)\n"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m"]}],"execution_count":15},{"cell_type":"code","source":"#!c1.8\n","metadata":{"cellId":"shv23weru76tepcprwr17"},"outputs":[],"execution_count":null}]}